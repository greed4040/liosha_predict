{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out of the book\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate a sequence of random numbers in [0, n_features)\n",
    "def generate_sequence(length, n_features):\n",
    "    return [randint(0, n_features-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_features):\n",
    "    encoding = list()\n",
    "    for value in sequence:\n",
    "        vector = [0 for _ in range(n_features)]\n",
    "        vector[value] = 1\n",
    "        encoding.append(vector)\n",
    "    return array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate one example for an lstm\n",
    "def generate_example(length, n_features, out_index):\n",
    "    # generate sequence\n",
    "    sequence = generate_sequence(length+1, n_features)\n",
    "    # one hot encode\n",
    "    print(sequence)\n",
    "    encoded = one_hot_encode(sequence[:length], n_features)\n",
    "    # reshape sequence to be 3D\n",
    "    X = encoded.reshape((1, length, n_features))\n",
    "    \n",
    "    # select output\n",
    "    y_encoded = one_hot_encode(sequence[length:length+1], n_features)\n",
    "    y = y_encoded.reshape(1, n_features)\n",
    "    return X, y\n",
    "\n",
    "# define model\n",
    "length = 5\n",
    "n_features = 10\n",
    "out_index = 4\n",
    "model = Sequential()\n",
    "model.add(LSTM(25, input_shape=(length, n_features)))\n",
    "model.add(Dense(n_features, activation= 'softmax' ))\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam' , metrics=[ 'acc' ])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "for i in range(10000):\n",
    "    X, y = generate_example(length, n_features, out_index)\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print('=')\n",
    "    model.fit(X, y, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "correct = 0\n",
    "for i in range(100):\n",
    "    X, y = generate_example(length, n_features, out_index)\n",
    "    yhat = model.predict(X)\n",
    "    if one_hot_decode(yhat) == one_hot_decode(y):\n",
    "        correct += 1\n",
    "print( 'Accuracy: %f' % ((correct/100)*100.0))\n",
    "\n",
    "# prediction on new data\n",
    "X, y = generate_example(length, n_features, out_index)\n",
    "yhat = model.predict(X)\n",
    "print( 'Sequence: %s' % [one_hot_decode(x) for x in X])\n",
    "print( 'Expected: %s' % one_hot_decode(y))\n",
    "print( 'Predicted: %s' % one_hot_decode(yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
